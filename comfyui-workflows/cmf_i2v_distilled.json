{
    "2": {
        "inputs": {
            "samples": [
                "96",
                0
            ],
            "vae": [
                "9",
                0
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode Video"
        }
    },
    "3": {
        "inputs": {
            "text": "blur, watermark, low quality, static, distorted, ugly, deformed, extra limbs, bad anatomy, overexposed, underexposed, glitch, noise, grain, still frame, worst quality, JPEG artifacts",
            "clip": [
                "25",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "Negative Prompt"
        }
    },
    "4": {
        "inputs": {
            "sage_attention": "auto",
            "allow_compile": false,
            "model": [
                "62",
                0
            ]
        },
        "class_type": "PathchSageAttentionKJ",
        "_meta": {
            "title": "SageAttention (High-Noise)"
        }
    },
    "5": {
        "inputs": {
            "sage_attention": "auto",
            "allow_compile": false,
            "model": [
                "63",
                0
            ]
        },
        "class_type": "PathchSageAttentionKJ",
        "_meta": {
            "title": "SageAttention (Low-Noise)"
        }
    },
    "6": {
        "inputs": {
            "enable_fp16_accumulation": true,
            "model": [
                "62",
                0
            ]
        },
        "class_type": "ModelPatchTorchSettings",
        "_meta": {
            "title": "FP16 Accumulation (High-Noise)"
        }
    },
    "7": {
        "inputs": {
            "enable_fp16_accumulation": true,
            "model": [
                "63",
                0
            ]
        },
        "class_type": "ModelPatchTorchSettings",
        "_meta": {
            "title": "FP16 Accumulation (Low-Noise)"
        }
    },
    "9": {
        "inputs": {
            "vae_name": "Wan2.1_VAE.pth"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "Load Wan VAE"
        }
    },
    "19": {
        "inputs": {
            "frame_rate": 16,
            "loop_count": 0,
            "filename_prefix": "CMF_I2V",
            "format": "video/h264-mp4",
            "pix_fmt": "yuv420p",
            "crf": 16,
            "save_metadata": false,
            "trim_to_audio": false,
            "pingpong": false,
            "save_output": true,
            "no_preview": false,
            "images": [
                "376",
                0
            ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
            "title": "Video Combine (MP4 @ 16fps)"
        }
    },
    "20": {
        "inputs": {
            "value": [
                "372",
                0
            ]
        },
        "class_type": "INTConstant",
        "_meta": {
            "title": "Frame Count"
        }
    },
    "21": {
        "inputs": {
            "width": [
                "369",
                3
            ],
            "height": [
                "369",
                4
            ],
            "length": [
                "20",
                0
            ],
            "batch_size": 1,
            "positive": [
                "29",
                0
            ],
            "negative": [
                "3",
                0
            ],
            "vae": [
                "9",
                0
            ],
            "start_image": [
                "369",
                0
            ]
        },
        "class_type": "WanImageToVideo",
        "_meta": {
            "title": "WanImageToVideo"
        }
    },
    "25": {
        "inputs": {
            "clip_name": "umt5_xxl_fp16.safetensors",
            "type": "wan",
            "device": "cpu"
        },
        "class_type": "CLIPLoader",
        "_meta": {
            "title": "Load CLIP (UMT5-XXL)"
        }
    },
    "26": {
        "inputs": {
            "value": 6
        },
        "class_type": "INTConstant",
        "_meta": {
            "title": "Total Steps (6)"
        }
    },
    "27": {
        "inputs": {
            "unet_name": "wan2.2_i2v_A14b_high_noise_scaled_fp8_e4m3_lightx2v_4step_comfyui.safetensors",
            "weight_dtype": "fp8_e4m3fn"
        },
        "class_type": "UNETLoader",
        "_meta": {
            "title": "Load High-Noise UNET (Distilled)"
        }
    },
    "28": {
        "inputs": {
            "unet_name": "wan2.2_i2v_A14b_low_noise_scaled_fp8_e4m3_lightx2v_4step_comfyui.safetensors",
            "weight_dtype": "default"
        },
        "class_type": "UNETLoader",
        "_meta": {
            "title": "Load Low-Noise UNET (Distilled)"
        }
    },
    "29": {
        "inputs": {
            "text": "PLACEHOLDER_MOTION_PROMPT",
            "clip": [
                "25",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "Motion Prompt"
        }
    },
    "30": {
        "inputs": {
            "value": 960
        },
        "class_type": "INTConstant",
        "_meta": {
            "title": "Scale To Length (960)"
        }
    },
    "34": {
        "inputs": {
            "image": "PLACEHOLDER_IMAGE.png"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Hero Frame"
        }
    },
    "36": {
        "inputs": {
            "lora_name": "wan2.2_i2v_A14b_high_noise_lora_rank64_lightx2v_4step_1022.safetensors",
            "strength_model": 2.0,
            "model": [
                "27",
                0
            ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
            "title": "Load Distillation LoRA (High-Noise)"
        }
    },
    "62": {
        "inputs": {
            "lora_name": "Wan2.2-Fun-A14B-InP-high-noise-MPS.safetensors",
            "strength_model": 0.5,
            "model": [
                "36",
                0
            ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
            "title": "Load Dynamics LoRA (High-Noise)"
        }
    },
    "63": {
        "inputs": {
            "lora_name": "Wan2.2-Fun-A14B-InP-low-noise-HPS2.1.safetensors",
            "strength_model": 0.5,
            "model": [
                "28",
                0
            ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
            "title": "Load Dynamics LoRA (Low-Noise)"
        }
    },
    "93": {
        "inputs": {
            "shift": 5,
            "model": [
                "7",
                0
            ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
            "title": "ModelSampling (Low-Noise, shift=5)"
        }
    },
    "94": {
        "inputs": {
            "add_noise": "enable",
            "noise_seed": 123456789,
            "steps": [
                "26",
                0
            ],
            "cfg": 1,
            "sampler_name": "euler",
            "scheduler": "normal",
            "start_at_step": 0,
            "end_at_step": [
                "97",
                0
            ],
            "return_with_leftover_noise": "enable",
            "model": [
                "95",
                0
            ],
            "positive": [
                "21",
                0
            ],
            "negative": [
                "21",
                1
            ],
            "latent_image": [
                "21",
                2
            ]
        },
        "class_type": "KSamplerAdvanced",
        "_meta": {
            "title": "KSampler Pass 1 (High-Noise)"
        }
    },
    "95": {
        "inputs": {
            "shift": 5,
            "model": [
                "6",
                0
            ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
            "title": "ModelSampling (High-Noise, shift=5)"
        }
    },
    "96": {
        "inputs": {
            "add_noise": "disable",
            "noise_seed": 214,
            "steps": [
                "26",
                0
            ],
            "cfg": 1,
            "sampler_name": "euler",
            "scheduler": "normal",
            "start_at_step": [
                "97",
                0
            ],
            "end_at_step": 10000,
            "return_with_leftover_noise": "disable",
            "model": [
                "93",
                0
            ],
            "positive": [
                "21",
                0
            ],
            "negative": [
                "21",
                1
            ],
            "latent_image": [
                "94",
                0
            ]
        },
        "class_type": "KSamplerAdvanced",
        "_meta": {
            "title": "KSampler Pass 2 (Low-Noise)"
        }
    },
    "97": {
        "inputs": {
            "value": 2
        },
        "class_type": "INTConstant",
        "_meta": {
            "title": "Switch Step (2)"
        }
    },
    "369": {
        "inputs": {
            "aspect_ratio": "original",
            "proportional_width": 1,
            "proportional_height": 1,
            "fit": "crop",
            "method": "lanczos",
            "round_to_multiple": "16",
            "scale_to_side": "longest",
            "scale_to_length": [
                "30",
                0
            ],
            "background_color": "#000000",
            "image": [
                "370",
                0
            ]
        },
        "class_type": "LayerUtility: ImageScaleByAspectRatio V2",
        "_meta": {
            "title": "Scale by Aspect Ratio"
        }
    },
    "370": {
        "inputs": {
            "width": 1088,
            "height": 1920,
            "upscale_method": "lanczos",
            "keep_proportion": "crop",
            "pad_color": "0, 0, 0",
            "crop_position": "center",
            "divisible_by": 16,
            "device": "cpu",
            "image": [
                "34",
                0
            ]
        },
        "class_type": "ImageResizeKJv2",
        "_meta": {
            "title": "Resize Input (1088x1920)"
        }
    },
    "371": {
        "inputs": {
            "value": 4
        },
        "class_type": "INTConstant",
        "_meta": {
            "title": "Duration Seconds (4)"
        }
    },
    "372": {
        "inputs": {
            "expression": "(a * 16) + 1",
            "a": [
                "371",
                0
            ]
        },
        "class_type": "MathExpression|pysssss",
        "_meta": {
            "title": "Calculate Frames (4s @ 16fps = 65)"
        }
    },
    "376": {
        "inputs": {
            "width": 540,
            "height": 960,
            "interpolation": "lanczos",
            "method": "fill / crop",
            "condition": "always",
            "multiple_of": 0,
            "image": [
                "2",
                0
            ]
        },
        "class_type": "ImageResize+",
        "_meta": {
            "title": "Resize Output (540x960)"
        }
    }
}